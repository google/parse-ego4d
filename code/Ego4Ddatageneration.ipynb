{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The PARSE-ego4D Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YcC2mubbUO1"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import random\n",
    "import json\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1712340144636,
     "user": {
      "displayName": "Steve Abreu",
      "userId": "09107865187543327732"
     },
     "user_tz": 240
    },
    "id": "CBDG8MlRyZXs"
   },
   "outputs": [],
   "source": [
    "# @title Prompt engineering\n",
    "\n",
    "FIX_JSON_PROMPT = \"\"\"\\\n",
    "{full_prompt}\n",
    "{response}\n",
    "This response returned the following JSON decode error: {e}. \\\n",
    "Please re-generate the response to fix the error:\n",
    "\"\"\"\n",
    "\n",
    "ANOTHER_SUGGESTION_PROMPT = \"\"\"\\\n",
    "{full_prompt}\n",
    "{response}\n",
    "\n",
    "Thank you for generating this response. Please now generate another JSON \\\n",
    "response in the same manner as before, but with a different suggestion. \\\n",
    "Do not reuse the same response from above, but rather think about a new \\\n",
    "response from scratch. Make it an even more useful suggestion for the user.\n",
    "\n",
    "Response:\n",
    "\"\"\"\n",
    "\n",
    "sys_prompt_actions = \"\"\"\\\n",
    "Here is a list of available apps that you can use to recommend actions to the user:\n",
    "\n",
    "Multimodal search (MMS): This application will take in the current camera input and a text query and run a multimodal search using the text query with the image as context. MMS can recognize objects, identify plants and animals, provide nutritional information, look up information, and answer general knowledge questions. It takes language and image input, and outputs text.\n",
    "\n",
    "API format:\n",
    "action: \"mms\"\n",
    "params:\n",
    "  query: str, adapted from the user query\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"How much does this cost?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"How much sugar is in this bar?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"Tell me about this book?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"What is this painting? Who is it by? Is it popular?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"What is the common name for this plant?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"Is this gluten free?\"}}\n",
    "{\"action\": \"mms\", \"params\": {\"query\": \"Where can I buy this?\"}}\n",
    "\n",
    "Assistant: This is the Android device assistant that has access to system apps. Basic apps that can be called from the Assistant include: `Notes`, `Timer`, `Stopwatch`, `Alarm`, `Email`, `Music`, `Phone`, `Contacts`, `Messages`, `Settings`, `Calculator`. Additionally, the Assistant can control smart home gadgets, access notifications, and others.\n",
    "\n",
    "API format:\n",
    "action: \"assistant\"\n",
    "params:\n",
    "  query: str, adapted from the user query\n",
    "  hint: str, hint for the assistant about what app/system to use for handling this request (optional)\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"Do pineapples need to be refrigerated?\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"What is memorial day?\", \"hint\": \"search\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"What size tank does the Yamaha YZ125 have?\", \"hint\": \"search\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"How long does it take a car battery to die if you leave the lights on?\", \"hint\": \"search\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"How many carbs are in Buddha gluten-free hamburger buns?\", \"hint\": \"search\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"How long does marking spray paint last on cement?\", \"hint\": \"search\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"What song is this?\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"flip a coin\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"how much data have I used this month?\", \"hint\": \"settings\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"27.1 * 91\", \"hint\": \"calculator\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"turn off data\", \"hint\": \"settings\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"turn on low battery mode\", \"hint\": \"settings\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"remove ibuprofen from the shopping list\", \"hint\": \"notes\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"check if <name> responded to my email\", \"hint\": \"email\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"check for new emails\", \"hint\": \"email\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"meetings last thursday\", \"hint\": \"calendar\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"do I have anything scheduled for tonight?\", \"hint\": \"calendar\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"play music that compliments this view\", \"hint\": \"music\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"turn volume to 70%\", \"hint\": \"music\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"turn volume to 70%\", \"hint\": \"music\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"dim lights to 20%\", \"hint\": \"home\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"set AC to 70 degrees\", \"hint\": \"home\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"play inception on chromecast\", \"hint\": \"home\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"set alarm for 8am\", \"hint\": \"alarm\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"check active stopwatch\", \"hint\": \"stopwatch\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"start stopwatch\", \"hint\": \"stopwatch\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"set timer for 5 minutes\", \"hint\": \"timer\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"weather this sunday\", \"hint\": \"weather\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"next full moon\", \"hint\": \"weather\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"send message to <name>\", \"hint\": \"messages\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"tell <name> I'll be 5 minutes late\", \"hint\": \"messages\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"call <name>\", \"hint\": \"phone\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"show notifications\", \"hint\": \"notifications\"}}\n",
    "{\"action\": \"assistant\", \"params\": {\"query\": \"show notifications\", \"hint\": \"notifications\"}}\n",
    "\n",
    "Memory: The memory app can store memories and retrieve them later. Memories can be enrolled manually in the app, by the user telling the memory app to remember something explicitly. Memories can also be automatically enrolled without requiring any action from the user. For example, if the user is looking at a shopping list, the memory app might automatically remember that shopping list so that it can be retrieved later.\n",
    "\n",
    "API format:\n",
    "action: \"memory\"\n",
    "params:\n",
    "  query: str, adapted from the user query\n",
    "  memory_query_type: str, one of \"store\", \"retrieve\"\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember this\", \"memory_query_type\": \"store\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember to never order this wine again\", \"memory_query_type\": \"store\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember what I ordered here\", \"memory_query_type\": \"store\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember what John is allergic to\", \"memory_query_type\": \"store\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember this place\", \"memory_query_type\": \"store\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"remember this\", \"memory_query_type\": \"retrieve\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"what is john allergic to?\", \"memory_query_type\": \"retrieve\"}}\n",
    "{\"action\": \"memory\", \"params\": {\"query\": \"what do I have to buy here?\", \"memory_query_type\": \"retrieve\"}}\n",
    "\n",
    "Language: The language application is an application that can either transcribe what the user is hearing right now, translate what the user is reading or hearing, determining what language is spoken.\n",
    "\n",
    "API format:\n",
    "\"action\": \"language\"\n",
    "  \"params\"\n",
    "    \"query\": str, adapted from the user query\n",
    "    \"language_query_type\": str, one of \"translate\", \"transcribe\", \"detect\", \"summarize\"\n",
    "    \"source_language\": str, optional, only specified if the user specified it\n",
    "    \"target_language\": str, optional, only specified if the user specified it\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"What language is this person speaking?\", \"language_query_type\": \"detect_language\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"Is he speaking Japanese?\", \"language_query_type\": \"detect_language\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"transcribe from spanish\", \"language_query_type\": \"transcribe\", \"source_language\": \"spanish\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"translate from french to english\", \"language_query_type\": \"translate\", \"source_language\": \"french\", \"target_language\": \"english\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"transcribe\", \"language_query_type\": \"transcribe\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"translate text\", \"language_query_type\": \"translate\"}}\n",
    "{\"action\": \"language\", \"params\": {\"query\": \"summarize what we just talked about\", \"language_query_type\": \"summarize\"}}\n",
    "\n",
    "Maps: The maps application can help the user find relevant places nearby, plan routes, estimate distances and navigate to places.\n",
    "\n",
    "API format:\n",
    "action: \"maps\"\n",
    "  params:\n",
    "    query: str, adapted from the user query\n",
    "    mode: str, optional, one of \"walking\", \"cycling\", \"public_transport\", \"driving\", \"taxi\"\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"closest grocery store\"}}\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"gas station on the way to the airport\"}}\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"nearest Starbucks\", \"mode\": \"walking\"}}\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"directions home\"}}\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"What is the ETA?\"}}\n",
    "{\"action\": \"maps\", \"params\": {\"query\": \"Directions to the park\"}\n",
    "\n",
    "Instructions: This app can give detailed and step-by-step instructions to the user.\n",
    "\n",
    "API format:\n",
    "action: \"instructions\"\n",
    "params:\n",
    "  query: str, adapted from the user query\n",
    "\n",
    "And here are some example actions for this app:\n",
    "{\"action\": \"instructions\", \"params\": {\"query\": \"how to repair a bike tire\"}}\n",
    "{\"action\": \"instructions\", \"params\": {\"query\": \"How to knit a scarf?\"}}\n",
    "{\"action\": \"instructions\", \"params\": {\"query\": \"How do I bake a sourdough bread?\"}}\n",
    "{\"action\": \"instructions\", \"params\": {\"query\": \"How to perform basic first aid for cuts?\"}}\n",
    "\n",
    "Here is a list of proactive query examples for different contexts:\n",
    "\n",
    "If taking medicine, then log that medicine was likely taken, potentially store photo (mapping to app: Memory)\n",
    "If getting home, then notify for reminders/messages/memories that have location triggers  (mapping to app: Notifications, Memory)\n",
    "If arriving at store where items on shopping list can be found, then open shopping list (mapping to app: Assistant, Memory)\n",
    "If 2 hours until potluck, and I said I'm bringing apple pie, then show a reminder (mapping to app: Memory, Assistant, Calendar)\n",
    "If time to take antibiotics, based on doctor's prescription, then show a reminder (mapping to app: Memory, Assistant, Calendar)\n",
    "If engaging in a conversation, then enable Do Not Disturb in the system  (mapping to app: Asisstant)\n",
    "If eating something, then remember what was eaten (mapping to app: Memory)\n",
    "If driving, then auto Do-Not-Disturb, store activity log? (mapping to app: Asisstant, Memory)\n",
    "If my child is laughing in my home, then record image/video clip to memory/photos? (mapping to app: Memory)\n",
    "If leaving the office, then message partner that on the way home (mapping to app: Messages)\n",
    "If leaving a building, then offer directions to the next likely location (mapping to app: Maps)\n",
    "If in a meeting with person X / about subject Y, then reminder of unmentioned agenda items (mapping to app: Memory, Notifications)\n",
    "If looking at a landmark, then ask if user wants to learn about the history (mapping to app: Maps)\n",
    "If someone shows up at home while not there, then notify the user and allow talking to that person (mapping to app: Home (Nest))\n",
    "If starting / stopping exercise, then ask if the user wants to log the activity (mapping to app: Fitness)\n",
    "\n",
    "Here is a list of object-centered queries for different kinds of objects:\n",
    "\n",
    "Generic: What can I do with this?, Show carbon footprint, Show how to dispose of this, Send a photo of this to <name>, Remember this, Add to to-do list\n",
    "Smart home (Speaker): Music controls: pause, play, next, previous\n",
    "Smart home (Lamp): Change color\n",
    "Smart home (Lamp, AC): Dim, regulate, Turn on/off\n",
    "Book: Mark book as read, Listen as audiobook, Show reading history, Compare to other books from the same author\n",
    "Food: What can I make with this?, Show stock level at home, Show which of my saved recipes use this item, Log into nutrition tracker app, Tell me when I last consumed this, Assess freshness or expiry, Show product origin, Show nutrition, ingredients and allergens, Show product origin\n",
    "Household: Show user manual, Show tutorial for use\n",
    "Clothes or furniture: Show last cleaned, Mark as cleaned, Check warranty, Show materials, Show cleaning instructions, Change color\n",
    "Plants: Show care instructions, Predict health, Mark as watered, Show last watered, Mark as trimmed, Show last trimmed, Mark as soiled, Show last soiled\n",
    "\"\"\"\n",
    "\n",
    "example = \"\"\"\\\n",
    "Here is an example of this task:\n",
    "\n",
    "Input:\n",
    "   0 #C C looks around\n",
    "   1 #C C interacts with lady x\n",
    "   2 #C C looks around\n",
    "   3 #C C walks\n",
    "   4 #C C interacts\n",
    "   5 #C C looks around\n",
    "   6 #C C walks\n",
    "   7 #C C looks around\n",
    "   8 #C C walks\n",
    "   9 #C C looks around\n",
    "  10 #C C does something #unsure\n",
    "  11 #C C interacts\n",
    "  12 #C C walks\n",
    "  13 #C C interacts with man y\n",
    "  14 #C C walks\n",
    "  15 #C C interacts\n",
    "  16 #C C looks around\n",
    "  17 #C C walks\n",
    "  18 #C C interacts\n",
    "  19 #C C looks around\n",
    "  20 #C C walks\n",
    "  21 #C C interacts\n",
    "  22 #C C looks around\n",
    "  23 #C C walks\n",
    "  24 #C C looks around\n",
    "  25 #C C interacts\n",
    "  26 #C C looks around\n",
    "  27 #C C walks\n",
    "  28 #C C looks around in the supermarket.\n",
    "  29 #C C walks around next to coffee maker machines.\n",
    "  30 #C C looks towards a coffee maker machine.\n",
    "  31 #C C walks around next to coffee maker machines.\n",
    "  32 #C C looks towards a coffee maker machine.\n",
    "  33 #C C looks around a cup lid dispenser.\n",
    "  34 #C C walks around in the supermarket.\n",
    "  35 #C C looks towards a display counter.\n",
    "  36 #C C looks around in the supermarket.\n",
    "  37 #C C lifts a plastic tumbler.\n",
    "  38 #C C moves around in the supermarket.\n",
    "  39 #C C looks around a cup lid dispenser.\n",
    "  40 #C C looks around in the supermarket.\n",
    "  41 #C C walks around in the supermarket.\n",
    "  42 #C C views items on supermarket shelving.\n",
    "  43 #C C walks around in the supermarket.\n",
    "  44 #C C views items on supermarket shelving.\n",
    "\n",
    "Response:\n",
    "{\n",
    "  \"thoughts\": \"The user is in a supermarket, probably shopping. They have been \\\n",
    "walking around, probably looking for something. At line [28], they first \\\n",
    "looked around in the supermarket, so that would be a natural time for them to \\\n",
    "ask their AR glasses for help. It's unlikely that the AR glasses could help \\\n",
    "navigate the supermarket because I don't know of any service or app that would \\\n",
    "do that. However, they could ask the AR glasses to open their shopping list. \\\n",
    "Then it could display items one by one as the user goes through the \\\n",
    "supermarket.\",\n",
    "  \"intent\": {\n",
    "    \"timestamp\": 28,\n",
    "    \"description\": \"Open the shopping list\",\n",
    "    \"query\": \"Show me my shopping list\"\n",
    "  },\n",
    "  \"action\": {\n",
    "    \"action\": \"assistant\",\n",
    "    \"params\": {\n",
    "      \"query\": \"show me my shopping list\",\n",
    "      \"hint\": \"notes\"\n",
    "    }\n",
    "  },\n",
    "  \"confidence\": {\n",
    "    \"timing_confidence\": 0.8,\n",
    "    \"query_confidence\": 0.8,\n",
    "    \"action_confidence\": 0.9\n",
    "  },\n",
    "  \"assumptions\": {\n",
    "    \"system_assumptions\": \"the user has a shopping list\",\n",
    "    \"user_assumptions\": \"\"\n",
    "  },\n",
    "}\"\"\"\n",
    "\n",
    "narration_format = \"\"\"\\\n",
    "We will provide a narrated user journey in the following format:\n",
    "\n",
    "(...)\n",
    "#C C interacts with the man Y\n",
    "#C C raises a boot\n",
    "#C C wears the boot on her left leg\n",
    "#O The man Y walks out of the bedroom\n",
    "#O The man Y walks into the bedroom\n",
    "#O The man Y drops the boots on the floor\n",
    "(...)\n",
    "\n",
    "where #C shows that the sentence is about an action that you are doing, \\\n",
    "and #O shows that the sentence is about an action that someone else is doing.\\\n",
    "\"\"\"\n",
    "\n",
    "json_format = \"\"\"\\\n",
    "The format of your response should be in JSON, in which you first write out \\\n",
    "your thoughts, then write out the user query that the user would be asking in \\\n",
    "their particular situation, then the line of the narrations at which the user \\\n",
    "is asking the query, and finally the action that the AR glasses should take to \\\n",
    "respond to the user query. Here is the JSON response format:\n",
    "\n",
    "thoughts: str   # analyze situation, rationale for suggestion\n",
    "intent:\n",
    "  timestamp: int   # when to ask the query\n",
    "  description: str   # what the user may want to do in this situation\n",
    "  query: str   # query that the user might ask the glasses\n",
    "action:\n",
    "  action: str   # action that the glasses should take in response to the query\n",
    "  params: dict   # according to the action specification\n",
    "confidence:\n",
    "  timing_confidence: int   # how confident that this is a good time\n",
    "  query_confidence: int   # how confident that this is a useful/helpful query\n",
    "  action_confidence: int   # how confident that this is the correct and valid action\n",
    "assumptions:\n",
    "  system_assumptions: Optional[str]   # assumptions about the system state (e.g. memory)\n",
    "  user_assumptions: Optional[str]   # assumptions about the user (e.g. vegetarian)\\\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = f\"\"\"\\\n",
    "You are a user experience researcher and you are helping us collect a dataset \\\n",
    "of useful interactions for augmented reality (AR) glasses. We have a set of \\\n",
    "applications and services on the AR glasses already, and our current goal is \\\n",
    "to effectively link user queries to system actions on the AR glasses, in a \\\n",
    "wide variety of contextual settings and use case scenarios. To do this, we \\\n",
    "have a dataset of narrated user journeys, of what a particular user has been \\\n",
    "doing with their AR glasses in the last 10-30 minutes.\n",
    "\n",
    "{narration_format}\n",
    "\n",
    "{sys_prompt_actions.strip()}\n",
    "\n",
    "Given the narrations of what the user has been doing, your task is to read \\\n",
    "through the situation description and think about when the user would ask the \\\n",
    "AR glasses for help, and what they would ask their AR glasses to do for them, \\\n",
    "given the action list above that the AR glasses support. \\\n",
    "\n",
    "You can feel free to imagine additional circumstances that are not explicitly \\\n",
    "mentioned in the situation description. For example, if the situation only \\\n",
    "mentions that the user is walking around in the supermarket, you can imagine \\\n",
    "that the user is looking for a particular product, like cheese - even though \\\n",
    "'cheese' is never mentioned in the narration. \\\n",
    "\n",
    "You should pick the single most appropriate time at which the user would ask \\\n",
    "their AR glasses for help, and then respond with a query for the AR glasses. \\\n",
    "This query can be a question or a command.\n",
    "\n",
    "{json_format}\n",
    "\n",
    "{example}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-phgQO_bdd-"
   },
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U56e63ZDY5nc"
   },
   "outputs": [],
   "source": [
    "def get_gemini_model(model_name: str):\n",
    "    if model_name == \"mm\":\n",
    "        pass\n",
    "    elif model_name == \"lm\":\n",
    "        pass\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name: \", model_name)\n",
    "\n",
    "def get_gemini_response(gemini_model, query: str):\n",
    "    pass\n",
    "\n",
    "def load_ego4d_narration_data():\n",
    "    \"\"\"Load the Ego4D narration JSON file, from `annotations/narration.json`.\"\"\"\n",
    "    pass\n",
    "\n",
    "def check_db_connection():\n",
    "    \"\"\"Returns True if the database connection is successful, False otherwise.\"\"\"\n",
    "    pass\n",
    "\n",
    "def store_data(df_data):\n",
    "    \"\"\"Write all data to sheet. Raises an exception if writing fails.\"\"\"\n",
    "    pass\n",
    "\n",
    "def log_error(video_id: str, error: str):\n",
    "    \"\"\"Log failure. Returns True if successful, False otherwise.\"\"\"\n",
    "    pass\n",
    "\n",
    "def get_existing_video_ids():\n",
    "    \"\"\"Get a sorted list of all video IDs that are already processed.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxpz0EMEY5nc"
   },
   "outputs": [],
   "source": [
    "def flatten_mixed_dict(d):\n",
    "  \"\"\"Flattens a dictionary with a mix of one-level and two-level keys.\"\"\"\n",
    "  flattened_dict = {}\n",
    "  for outer_key, value in d.items():\n",
    "    if isinstance(value, dict):  # Check if the value is a dictionary (two-level key)\n",
    "      for inner_key, inner_value in value.items():\n",
    "        if isinstance(inner_value, dict):\n",
    "          flattened_dict[f\"{inner_key}\"] = json.dumps(inner_value)\n",
    "        else:\n",
    "          flattened_dict[f\"{inner_key}\"] = inner_value\n",
    "    else:  # Handle one-level key\n",
    "        flattened_dict[outer_key] = value\n",
    "  return flattened_dict\n",
    "\n",
    "\n",
    "def load_narration_data():\n",
    "  narration_data = load_ego4d_narration_data()\n",
    "\n",
    "  # create smaller dictionary without unused metadata\n",
    "  narration = {}\n",
    "  for vid_id in narration_data.keys():\n",
    "    narration[vid_id] = {}\n",
    "    for narr_pass in filter(lambda x: 'narration_pass' in x, narration_data[vid_id].keys()):\n",
    "      summaries = []\n",
    "      for summary in narration_data[vid_id][narr_pass]['summaries']:\n",
    "        summaries.append(summary['summary_text'])\n",
    "      narration_text = []\n",
    "      for narr in narration_data[vid_id][narr_pass]['narrations']:\n",
    "        narration_text.append(narr['narration_text'])\n",
    "      narration[vid_id][narr_pass] = summaries, narration_text\n",
    "\n",
    "  del narration_data\n",
    "  return narration\n",
    "\n",
    "\n",
    "def sample_narration(narration: dict[str, dict[str, str]], video_id: str, n_tries: int = 1):\n",
    "  \"\"\"Sample narration from the Ego4D narration dictionary.\n",
    "\n",
    "  Args:\n",
    "    narration: Ego4D narration dictionary\n",
    "    video_id: video id\n",
    "    n_tries: number of tries\n",
    "  Returns:\n",
    "    key, narr, summ: video_id, narration text, video summary (None, None, None)\n",
    "                     if failed to load\n",
    "  \"\"\"\n",
    "  for _ in range(n_tries):\n",
    "    if video_id is None:\n",
    "      key = list(narration.keys())[random.randint(0, len(narration)-1)]\n",
    "    else:\n",
    "      key = video_id\n",
    "\n",
    "    if key not in narration:\n",
    "      continue\n",
    "\n",
    "    if 'narration_pass_1' not in narration[key]:\n",
    "      continue\n",
    "\n",
    "    summ, narr = narration[key]['narration_pass_1']\n",
    "    if len(narr) == 0 or len(summ) == 0 or len(''.join(summ)) < 5:\n",
    "      continue\n",
    "\n",
    "    return key, narr, summ\n",
    "\n",
    "  return None, None, None\n",
    "\n",
    "\n",
    "def process_data(data):\n",
    "  df_data = []\n",
    "  keys = [\"thoughts\", \"intent\", \"action\", \"confidence\", \"assumptions\"]\n",
    "  for d in [e for e in data if e is not None and isinstance(e, dict)]:\n",
    "    sug1 = flatten_mixed_dict({k: d[k] for k in keys})\n",
    "    video = d['video']\n",
    "    sug1[\"video_id\"] = video['video_id']\n",
    "    sug1[\"batch_idx\"] = d['batch_idx']\n",
    "    sug1[\"batch_size\"] = d['batch_size']\n",
    "    sug1[\"model_name\"] = d['model_name']\n",
    "    sug1[\"time_added\"] = d['time_added']\n",
    "    sug1[\"user_prompt\"] = video['user_prompt']\n",
    "    sug1[\"summary\"] = video['summary']\n",
    "    # store\n",
    "    df_data.append(sug1)\n",
    "\n",
    "    if \"another_suggestion\" in d:\n",
    "      sug2 = flatten_mixed_dict({k: v for k, v in d[\"another_suggestion\"].items() if k not in [\"batch_idx\", \"model_name\"]})\n",
    "      sug2[\"video_id\"] = video['video_id']\n",
    "      sug2[\"batch_idx\"] = d['another_suggestion']['batch_idx']\n",
    "      sug2[\"model_name\"] = d['another_suggestion']['model_name']\n",
    "      sug2[\"batch_size\"] = d['another_suggestion']['batch_size']\n",
    "      sug2[\"time_added\"] = d['another_suggestion']['time_added']\n",
    "      sug2[\"user_prompt\"] = video['user_prompt']\n",
    "      sug2[\"summary\"] = video['summary']\n",
    "      # store\n",
    "      df_data.append(sug2)\n",
    "\n",
    "  df_data = pd.DataFrame(df_data)\n",
    "  return df_data\n",
    "\n",
    "def write_data(data):\n",
    "  try:\n",
    "    df_data = process_data(data)\n",
    "    store_data(df_data)\n",
    "    return True\n",
    "  except Exception as e:\n",
    "    print(\"EXCEPTION when writing data\", type(e), e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OF58Q8aSutsJ"
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "  def __init__(self, model_name: str):\n",
    "    \"\"\"Data Generator.\n",
    "\n",
    "    Args:\n",
    "      model_name: model name, either \"lm\" or \"mm\"\n",
    "    \"\"\"\n",
    "    # load data from CNS\n",
    "    print(\"Loading Ego4D narration data\", end=\"\\r\")\n",
    "    self.narration = load_narration_data()\n",
    "    print(\"Successfully loaded narration data\")\n",
    "\n",
    "    # initialize gemini model\n",
    "    self.model_name = model_name\n",
    "    self.gemini_model = get_gemini_model(model_name)\n",
    "\n",
    "    # make sure data storage is set up\n",
    "    assert check_db_connection()\n",
    "\n",
    "\n",
    "  def get_llm_responses(self, full_prompt: str) -> dict[str, str]:\n",
    "    \"\"\"Get LLM response.\n",
    "\n",
    "    Args:\n",
    "      full_prompt: full prompt\n",
    "    Returns:\n",
    "      response_data (dict): response data in the specified JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    # get initial response\n",
    "    response = get_gemini_response(self.gemini_model, full_prompt)\n",
    "\n",
    "    # try parsing JSON - if it fails, ask LLM to fix it\n",
    "    try:\n",
    "      response_data = json.loads(response)\n",
    "    except Exception as e:\n",
    "      if isinstance(e, json.decoder.JSONDecodeError):\n",
    "        # print(\"JSONDecodeError: trying to fix...\", e)\n",
    "        new_prompt = FIX_JSON_PROMPT.format(full_prompt=full_prompt, response=response, e=e)\n",
    "        response = get_gemini_response(self.gemini_model, new_prompt)\n",
    "        response_data = json.loads(response)\n",
    "      else:\n",
    "        return f\"Exception when fixing JSON: {type(e)} {e}\"\n",
    "\n",
    "    # ask model for another suggestion - if it fails, don't add it\n",
    "    try:\n",
    "      prompt2 = ANOTHER_SUGGESTION_PROMPT.format(full_prompt=full_prompt, response=response)\n",
    "      response2 = get_gemini_response(self.gemini_model, prompt2)\n",
    "      response_data2 = json.loads(response2)\n",
    "      response_data['another_suggestion'] = response_data2\n",
    "    except Exception as e:\n",
    "      # TODO: log that the second suggestion failed\n",
    "      # print(\"EXCEPTION when asking for another suggestion\", type(e), e)\n",
    "      return response_data\n",
    "    return response_data\n",
    "\n",
    "\n",
    "  def annotate_video(\n",
    "    self, video_id: str, max_n_sentences: int = 150, iterator: tqdm = None,\n",
    "    min_n_sentences: int = 50,\n",
    "  ) -> list[dict[str, str]]:\n",
    "    \"\"\"Annotate a single video from the given video_id, and store the results.\"\"\"\n",
    "    # load narration & summary\n",
    "    x, narr, summ = sample_narration(self.narration, video_id)\n",
    "    if x is None or x != video_id:\n",
    "      log_error(video_id, \"Failed to load narrations\")\n",
    "      return None\n",
    "\n",
    "    # split narrations into batches of `max_n_sentences` lines\n",
    "    list_indexed_narrations = []\n",
    "    for idx in range(1 + len(narr) // max_n_sentences):\n",
    "      narr_sub = narr[idx * max_n_sentences:(idx + 1) * max_n_sentences]\n",
    "      ind_narr = '\\n'.join([f\"{i:3} {e}\" for i, e in enumerate(narr_sub)])\n",
    "      list_indexed_narrations.append(ind_narr)\n",
    "\n",
    "    data = []\n",
    "    # iterate over narration batches\n",
    "    for batch_idx, indexed_narrations in enumerate(list_indexed_narrations):\n",
    "      # set postfix on the tqdm iterator\n",
    "      if iterator is not None:\n",
    "        postfix_str = f\"video {video_id.split('-')[0]}\"\n",
    "        postfix_str += f\", batch {batch_idx+1}/{len(list_indexed_narrations)}\"\n",
    "        iterator.set_postfix_str(postfix_str)\n",
    "\n",
    "      # make sure there are enough sentences in this batch\n",
    "      if len(indexed_narrations.split(\"\\n\")) < min_n_sentences:\n",
    "        if batch_idx == 0:\n",
    "          log_error(video_id, f\"Less than {min_n_sentences} sentences in this batch, skipping.\")\n",
    "        break\n",
    "\n",
    "      # setup prompts\n",
    "      user_prompt = f\"\\n{indexed_narrations}\\n\\nResponse:\\n\"\n",
    "      full_prompt = f\"\\n{system_prompt}\\n\\n{user_prompt}\"\n",
    "\n",
    "      # generate LLM response\n",
    "      try:\n",
    "        d = self.get_llm_responses(full_prompt)\n",
    "      except Exception as e:\n",
    "        log_error(video_id, f\"Exception raised when generating LLM response: {type(e)} {e}\")\n",
    "      else:\n",
    "        if isinstance(d, dict):\n",
    "          # parsed successfully -> store data\n",
    "          d['batch_idx'] = batch_idx\n",
    "          d['model_name'] = self.model_name\n",
    "          d['batch_size'] = max_n_sentences\n",
    "          d['time_added'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "          if \"another_suggestion\" in d:\n",
    "            d['another_suggestion']['batch_idx'] = batch_idx\n",
    "            d['another_suggestion']['model_name'] = self.model_name\n",
    "            d['another_suggestion']['batch_size'] = max_n_sentences\n",
    "            d['another_suggestion']['time_added'] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "          d['video'] = {\n",
    "              'video_id': video_id,\n",
    "              'user_prompt': user_prompt,\n",
    "              'system_prompt': system_prompt,\n",
    "              'narration_pass': 'narration_pass_1',\n",
    "              'summary': '\\n'.join(summ),\n",
    "              'max_lines': max_n_sentences,\n",
    "          }\n",
    "          data.append(d)\n",
    "        elif isinstance(d, str):\n",
    "          log_error(video_id, d)\n",
    "        else:\n",
    "          print(\"ERROR: unrecognized return type from get_llm_responses\")\n",
    "\n",
    "      # write this batch's output to the google sheet\n",
    "      if write_data(data):\n",
    "        data = []\n",
    "\n",
    "    # make sure all data from this video is written to the google sheet\n",
    "    if len(data) > 0:\n",
    "      if not write_data(data):\n",
    "        print(\"failed to write datato sheet\")\n",
    "        return data\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3v78_1RbZH9"
   },
   "source": [
    "## Annotate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 28993,
     "status": "ok",
     "timestamp": 1712339914909,
     "user": {
      "displayName": "Steve Abreu",
      "userId": "09107865187543327732"
     },
     "user_tz": 240
    },
    "id": "qaVyVzY-3r-Z",
    "outputId": "20e289d5-4e74-41f7-887a-d00e307a30de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ego4D narration data\rSuccessfully loaded narration data\n"
     ]
    }
   ],
   "source": [
    "datagen = DataGenerator(model_name=\"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "height": 49,
     "referenced_widgets": [
      "6c949c8f404948d981b316bb39e0676b",
      "624e2649f3ba454484dea3a4c1bd4193",
      "26b15fdf3b5348ee8ea9ef29739126e3",
      "555b98125e1d4e51b60450348262666f",
      "3806b0fa34704f219440b82e91aa14d7",
      "b962b2375a7740eb9faef725d1e9f457",
      "6d15955466d442fa91848a731a404bdd",
      "b5445bbe0f574284b8d65f68a1ee124e",
      "d3fa984bf291470195533c62857c4c9d",
      "6064d63ed308466081f666b101a9673a",
      "30bdc3e05e4b464a8421a4b96134f893"
     ]
    },
    "executionInfo": {
     "elapsed": 79562,
     "status": "ok",
     "timestamp": 1712340000656,
     "user": {
      "displayName": "Steve Abreu",
      "userId": "09107865187543327732"
     },
     "user_tz": 240
    },
    "id": "pdVkDztC_ibk",
    "outputId": "1626565e-95cd-4dc8-fc47-35efd3837a43"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c949c8f404948d981b316bb39e0676b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Ego4D videos:   0%|                                                                                           …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "existing_video_ids = get_existing_video_ids()\n",
    "keys = sorted(list(set(datagen.narration.keys()).difference(existing_video_ids)))[::-1]\n",
    "iterator = tqdm(enumerate(keys), total=len(keys), leave=True, ncols=750, desc=\"Ego4D videos\")\n",
    "for idx, video_id in iterator:\n",
    "  data = datagen.annotate_video(video_id, iterator=iterator, max_n_sentences=200, min_n_sentences=50)\n",
    "  if data is not None:\n",
    "    # failed to save data -> print and continue\n",
    "    print(json.dumps(data, indent=2), end=\"\\n\" + \"-\"*20 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2-6mglNZ6_P"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "last_runtime": {
    "build_target": "//learning/language/tunelab/tunekit/colab:colab_notebook",
    "kind": "private"
   },
   "provenance": [
    {
     "file_id": "1ONU0u5fVc1Y_YNTOIgU4Os8FlJMrV0yF",
     "timestamp": 1712340079817
    },
    {
     "file_id": "12DKk7HH18_tLC_rZ2VdKRSr8c9OcMv1r",
     "timestamp": 1710776100619
    },
    {
     "file_id": "1_XRPw0T6qvMb2AckTPZ2eT-EdKE0pfsj",
     "timestamp": 1710156094744
    },
    {
     "file_id": "/piper/depot/google3/learning/gemini/deployment/colab/multimodal_sax_tutorial.ipynb",
     "timestamp": 1700247341572
    },
    {
     "file_id": "/piper/depot/google3/learning/gemini/deployment/colab/multimodal_sax_tutorial.ipynb",
     "timestamp": 1691714567013
    },
    {
     "file_id": "/piper/depot/google3/learning/gemini/deployment/colab/multimodal_sax_tutorial.ipynb",
     "timestamp": 1686853328774
    },
    {
     "file_id": "1Sh6OqBhiGTCtElLCxPpCctczUZABtvhF",
     "timestamp": 1686148084741
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26b15fdf3b5348ee8ea9ef29739126e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5445bbe0f574284b8d65f68a1ee124e",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3fa984bf291470195533c62857c4c9d",
      "value": 2
     }
    },
    "30bdc3e05e4b464a8421a4b96134f893": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3806b0fa34704f219440b82e91aa14d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "750px"
     }
    },
    "555b98125e1d4e51b60450348262666f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6064d63ed308466081f666b101a9673a",
      "placeholder": "​",
      "style": "IPY_MODEL_30bdc3e05e4b464a8421a4b96134f893",
      "value": " 2/2 [01:19&lt;00:00, 41.86s/it, video 3e08beb0, batch 2/2]"
     }
    },
    "6064d63ed308466081f666b101a9673a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "624e2649f3ba454484dea3a4c1bd4193": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b962b2375a7740eb9faef725d1e9f457",
      "placeholder": "​",
      "style": "IPY_MODEL_6d15955466d442fa91848a731a404bdd",
      "value": "Ego4D videos: 100%"
     }
    },
    "6c949c8f404948d981b316bb39e0676b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_624e2649f3ba454484dea3a4c1bd4193",
       "IPY_MODEL_26b15fdf3b5348ee8ea9ef29739126e3",
       "IPY_MODEL_555b98125e1d4e51b60450348262666f"
      ],
      "layout": "IPY_MODEL_3806b0fa34704f219440b82e91aa14d7"
     }
    },
    "6d15955466d442fa91848a731a404bdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5445bbe0f574284b8d65f68a1ee124e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b962b2375a7740eb9faef725d1e9f457": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3fa984bf291470195533c62857c4c9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
